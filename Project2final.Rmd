---
title: "HW 8: Linear Models with Categorical Regressors"
author: "Your Name"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
---
```{r init, include=F}
library(ezids)
library(data.table)
library(dplyr)
library(ggplot2)
library(magrittr)
library(forcats)
library(stringr)
library(scales)
```

```{r setup, include=FALSE}
# Some of common RMD options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
knitr::opts_chunk$set(warning = F, message = F)
# Can globally set option for number display format.
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
```

```{r}
app_train <- read.csv('application_train.csv')
print(dim(app_train))
head(app_train)
```
The training data has 307511 rows i.e. each one a separate loan and 122 features/columns including the TARGET (the label we want to predict).

```{r}
app_test <- read.csv('application_test.csv')
print(dim(app_test))
head(app_test)
```

The testing data has 48744 rows i.e. each one a separate loan and 121 features/columns which does not include the TARGET column. Testing dataset is considerably smaller than train data.

```{r}
table(app_train$TARGET)

```


```{r}
app_train$TARGET <- as.integer(app_train$TARGET)
hist(app_train$TARGET, xlab = 'TARGET', main = 'Histogram of TARGET column')
```
The dataset exhibits a significant class imbalance, with approximately 91.93% of the data belonging to one class and merely 8.07% to the other. Specifically, a substantial majority of loans were repaid on time compared to the minority of loans that were not repaid. In more advanced machine learning models, addressing this imbalance can be accomplished by assigning weights to the classes based on their representation in the dataset, ensuring a more reflective learning process

```{r}
missing_values_summary <- function(data) {
  missing_count <- colSums(is.na(data))
  missing_percentage <- round((missing_count / nrow(data)) * 100, 2)
  missing_df <- data.frame(
    Column = names(missing_count),
    Missing_Values = missing_count,
    Missing_Percentage = missing_percentage
  )
  return(missing_df[order(-missing_df$Missing_Percentage), ])
}

missing_summary <- missing_values_summary(app_train)
print(missing_summary)

```


```{r}
count_columns_with_nulls <- function(data) {
  columns_with_nulls <- sum(colSums(is.na(data)) > 0)
  cat("Number of columns with missing values:", columns_with_nulls, "\n")
}

# Call the function with your dataframe (e.g., app_train)
count_columns_with_nulls(app_train)
```


```{r}
data_types <- sapply(app_train, function(x) class(x))
data_types_counts <- table(data_types)

# Print the counts of each data type
print(data_types_counts)
```


```{r}
object_columns <- sapply(app_train, function(x) is.character(x) | is.factor(x))
unique_counts <- sapply(app_train[, object_columns], function(x) length(unique(x)))

# Print the counts of unique values in object-type columns
print(unique_counts)
```


```{r}
le_count <- 0
for (col in names(app_train)) {
  # Check if the column is of type 'character' or 'factor'
  if (is.character(app_train[[col]]) || is.factor(app_train[[col]])) {
    # If 2 or fewer unique categories
    if (length(unique(app_train[[col]])) <= 2) {
      # Convert to factor and encode the levels
      app_train[[col]] <- factor(app_train[[col]])
      app_test[[col]] <- factor(app_test[[col]])
      
      # Keep track of how many columns were label encoded
      le_count <- le_count + 1
    }
  }
}

cat(sprintf("%d columns were label encoded.\n", le_count))
```


```{r}
library(caret)

one_hot_encode <- function(data) {
  # Identify non-numeric and non-integer columns
  non_numeric_cols <- names(data)[!sapply(data, is.numeric) & !sapply(data, is.integer)]
  
  # Exclude non-numeric and non-integer columns from encoding
  categorical_cols <- setdiff(names(data), non_numeric_cols)
  
  # Exclude the "TARGET" column, assuming it's your response variable
  categorical_cols <- setdiff(categorical_cols, "TARGET")
  
  if (length(categorical_cols) == 0) {
    # No columns found for one-hot encoding
    return(data)
  }
  
  # Perform one-hot encoding using caret's dummyVars
  formula_text <- as.formula(paste("~ . + 0"))
  dummy_formula <- dummyVars(formula_text, data = data[, categorical_cols, drop = FALSE])
  encoded_data <- predict(dummy_formula, newdata = data[, categorical_cols, drop = FALSE])
  
  # Combine original and encoded columns
  final_data <- cbind(data, encoded_data)
  
  return(final_data)
}


app_train <- one_hot_encode(app_train)
app_test <- one_hot_encode(app_test)

```

```{r}
# Separate target variable from training data
train_labels <- app_train$TARGET
train_data <- app_train[, !names(app_train) %in% c("TARGET")]

# Identify common columns between training and testing data
common_columns <- intersect(names(app_train), names(app_test))

# Select common columns from training data
aligned_train_data <- app_train[, common_columns]

# Select common columns from testing data
aligned_test_data <- app_test[, common_columns]

# Add target variable back to aligned training data
aligned_training_data <- cbind(aligned_train_data, train_labels)

# Print shapes of aligned training and testing data
print(paste("Training Features shape:", dim(aligned_training_data)))
print(paste("Testing Features shape:", dim(aligned_test_data)))
```


```{r}

```


```{r}

```

```{r}

```


```{r}

```


```{r}

```
